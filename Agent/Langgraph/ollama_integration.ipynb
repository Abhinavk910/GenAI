{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hi\n",
      "Assistant: Hello. How can I assist you today?\n",
      "User: so what you know about sex\n",
      "Assistant: I can provide information on a wide range of topics related to sex. However, I want to emphasize that my goal is to provide accurate and respectful information, and I'll do my best to cater to your question while being mindful of boundaries and comfort levels.\n",
      "\n",
      "If you're looking for general information about sex, here are some topics I can cover:\n",
      "\n",
      "1. **Biological aspects**: How sex works Physically, reproductive systems, hormone regulation, etc.\n",
      "2. **Sexual health**: STIs (sexually transmitted infections), STDs (sexually transmitted diseases), pregnancy, and contraception methods.\n",
      "3. **Relationships**: Healthy relationships, communication, intimacy, and emotional connection during intimacy.\n",
      "4. **Sex education**: A general overview of what's considered healthy and normal in different cultures, countries, or age groups.\n",
      "5. **LGBTQ+ topics**: Information about sex from a non-judgmental perspective, including LGBTQ+ specific concerns.\n",
      "\n",
      "However, if you're looking for more in-depth information or personal advice on specific issues, I'll need to ask some questions to better understand your concerns and provide a more tailored response.\n",
      "\n",
      "Would you like me to:\n",
      "\n",
      "A) Provide general info on a specific topic\n",
      "B) Offer guidance on a particular issue or concern\n",
      "C) Ask follow-up questions to clarify or seek more information\n",
      "D) Provide resources for further learning\n",
      "\n",
      "Please let me know how I can assist you.\n",
      "User: hi\n",
      "Assistant: Hello. How can I assist you today?\n",
      "User: q\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1])\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        print(\"User: \" + user_input)\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = input()\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygenai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
