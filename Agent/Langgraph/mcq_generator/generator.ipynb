{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MCQGenerator:\n",
    "    api_key: str\n",
    "    model: str = 'gpt-4o-mini'\n",
    "    temperature: float = 0.3\n",
    "    max_retries: int = 10\n",
    "    llm: OpenAI = field(init=False)\n",
    "    prompt: PromptTemplate = field(init=False)\n",
    "    output_parser: StructuredOutputParser = field(init=False)\n",
    "    \n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.llm = ChatOpenAI(api_key=self.api_key, model=self.model, temperature=self.temperature)\n",
    "        self.setup_parser()\n",
    "\n",
    "    def setup_parser(self):\n",
    "        response_schemas = [\n",
    "            ResponseSchema(name=\"question\", description=\"The multiple choice question\"),\n",
    "            ResponseSchema(name=\"options\", description=\"A python list of 4 options for the question. Separated by comma(,)\"),\n",
    "            ResponseSchema(name=\"answer\", description=\"The correct option (A, B, C, or D)\"),\n",
    "            ResponseSchema(name=\"explanation\", description=\"Explanation of why the answer is correct\")\n",
    "        ]\n",
    "        self.output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "        \n",
    "        self.prompt = PromptTemplate(\n",
    "            template = (\n",
    "                \"Generate a unique multiple-choice question about {topic} with an initial complexity level of {complexity}.\\n\"\n",
    "                \"Question requirements:\\n\"\n",
    "                \"1. Adjust the difficulty based on the complexity level (1-5, where 1 is very simple and 5 is very complex).\\n\"\n",
    "                \"2. For lower complexity (1-2), focus on basic facts, definitions, or simple concepts.\\n\"\n",
    "                \"3. For higher complexity (4-5), include more advanced concepts, require analysis, or combine multiple ideas.\\n\"\n",
    "                \"4. Review this history of previous questions:\\n{history}\\n\"\n",
    "                \"5. If your generated question is similar to any in the history, INCREASE THE COMPLEXITY LEVEL BY 1 (up to a maximum of 5) and generate a new, more advanced question.\\n\"\n",
    "                \"6. Repeat step 5 until you generate a question that is significantly different from all questions in the history.\\n\"\n",
    "                \"7. Ensure the final question explores aspects or applications of the topic not covered in previous questions.\\n\"\n",
    "                \"8. Make all options plausible, but only one should be correct.\\n\"\n",
    "                \"{format_instructions}\\n\"\n",
    "                \"Formatting rules:\\n\"\n",
    "                \"1. Present the options as a Python list: ['A. option', 'B. option', 'C. option', 'D. option']\\n\"\n",
    "                \"2. The answer must be a single letter: 'A', 'B', 'C', or 'D'.\\n\"\n",
    "                \"3. Provide a clear explanation for the correct answer, matching the final complexity level.\\n\"\n",
    "                \"4. Include the final complexity level (1-5) used to generate the question in your response.\\n\"\n",
    "                \"5. Strictly adhere to the specified output format.\\n\"\n",
    "                \"6. Ensure the JSON is valid and can be parsed by a standard JSON parser.\\n\"\n",
    "                \"\\nBefore submitting, double-check that your question is not repeating or closely resembling any in the history.\"\n",
    "            ),\n",
    "            input_variables=['topic', 'complexity', 'history'],\n",
    "            partial_variables={'format_instructions': self.output_parser.get_format_instructions()}\n",
    "        ) \n",
    "\n",
    "    def generate_mcq(self, topic: str, complexity: int, history: List[str]) -> dict:\n",
    "        retries = 0\n",
    "        while retries < self.max_retries:\n",
    "            try:\n",
    "                formatted_history = \"\\n\".join([f\"- {q}\" for q in history])\n",
    "                _input = self.prompt.format(topic=topic, complexity=complexity, history=formatted_history)\n",
    "                output = self.llm.invoke(_input)\n",
    "                \n",
    "                if isinstance(output, AIMessage):\n",
    "                    content = output.content\n",
    "                    # print(content)\n",
    "                elif isinstance(output, list) and len(output) > 0 and isinstance(output[0], AIMessage):\n",
    "                    content = output[0].content\n",
    "                else:\n",
    "                    raise ValueError(\"Unexpected output format from ChatOpenAI\")\n",
    "                # print(content)\n",
    "                try:\n",
    "                    result = self.output_parser.parse(content)\n",
    "                except:\n",
    "                        \n",
    "                    def preprocess_json(json_string):\n",
    "                        # Replace single quotes with double quotes, but only for strings\n",
    "                        return re.sub(r\"'([^']*)'\", r'\"\\1\"', json_string)\n",
    "\n",
    "                    preprocessed_content = preprocess_json(content)\n",
    "                    result = self.output_parser.parse(preprocessed_content)\n",
    "                # print(content)\n",
    "                if isinstance(result.get('options'), list) and len(result['options']) == 4 and result['question'].lower() not in history:\n",
    "                    return result\n",
    "\n",
    "                print(\"Error: Options are not in the correct format. Retrying...\")\n",
    "                retries += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Parsing failed with error: {e}. Retrying... ({retries + 1}/{self.max_retries})\")\n",
    "                retries += 1\n",
    "\n",
    "        print(\"Failed to generate a valid MCQ after maximum retries. Click next and try again.\")\n",
    "        return {\n",
    "            'question': 'Could not generate a question. Press Next to try Again.',\n",
    "            'options': ['Option A', 'Option B', 'Option C', 'Option D'],\n",
    "            'answer': 'A',\n",
    "            'explanation': 'No explanation available.'\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_mcq(mcq_dict):\n",
    "    formatted_string = f\"\"\"Question: {mcq_dict['question']}\n",
    "\n",
    "        Options:\n",
    "        {mcq_dict['options'][0]}\n",
    "        {mcq_dict['options'][1]}\n",
    "        {mcq_dict['options'][2]}\n",
    "        {mcq_dict['options'][3]}\n",
    "\n",
    "        Correct Answer: {mcq_dict['answer']}\n",
    "\n",
    "        Explanation: {mcq_dict['explanation']}\"\"\"\n",
    "\n",
    "    return formatted_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How did the Great Fire of London in 1666 influence urban planning and fire safety regulations in modern London?\n",
      "\n",
      "        Options:\n",
      "        A. It led to the establishment of the London Fire Brigade in 1833.\n",
      "        B. It resulted in the creation of the first building codes to prevent wooden structures.\n",
      "        C. It caused the complete relocation of the city center to the West End.\n",
      "        D. It initiated the construction of the River Thames barrier.\n",
      "\n",
      "        Correct Answer: B\n",
      "\n",
      "        Explanation: The Great Fire of London in 1666 destroyed a significant portion of the city, leading to the implementation of the first building codes that mandated the use of brick and stone in construction to prevent future fires. This was a pivotal moment in urban planning and fire safety, directly influencing the architectural landscape of modern London and laying the groundwork for future regulations.\n"
     ]
    }
   ],
   "source": [
    "mcq_gen = MCQGenerator(api_key=api_key, temperature=0.7, max_retries=10)\n",
    "topic = \"london\"\n",
    "mcq = mcq_gen.generate_mcq(topic, 10,  [])\n",
    "print(format_mcq(mcq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
